# 💫 About Me:
## 💰 You can help me by Donating
🔭 localAIchat_Blender

  #                 ‎ ‎ ‎ ‎‎                                                                               ‎ ‎       ------------------------[![Ko-Fi](https://img.shields.io/badge/Ko--fi-F16061?style=for-the-badge&logo=ko-fi&logoColor=white)](https://ko-fi.com/sinbloo)---------------------- # 


‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎     ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎                  ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ 🌐 Socials:
‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ 
                                                                                                                                                ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎                                                                                           ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎‎ ‎‎[![Discord](https://img.shields.io/badge/Discord-%237289DA.svg?logo=discord&logoColor=white)](https://discord.gg/7YcZpDQZN2) [![X](https://img.shields.io/badge/X-black.svg?logo=X&logoColor=white)](https://x.com/sinbloostone) [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=YouTube&logoColor=white)](https://www.youtube.com/channel/UC9pZeI7EngXljcQ_eu737VQ) 


ok so you got the zip file now the zip fiel it self is not the addon 
the addon is in the folder now firt you need to unzip the fiel 
```
one yoy have the fiell  to get the addon go to 
F:\odin_grab\a_astitnet/
the one ---->├── addon/Advanced AI Communication.zip/# Blender addon 
├── ai mode/                 #  plase AI models here
│   ├── blobs/              # qwen3:4b & deepseek-r1:8b data_ext
│   └── manifests/          # Model registry files
├── niout/                   # Working chat files
│   ├── input.txt           # Your actual input file
│   ├── response.txt        # Your actual response file
│   └── model_config.txt    # Your actual config
├── chat.bat                 # Quick chat batch #file_disabled
├── check_python.bat        # NEW: Wat we use to run the model
├── model_manager.py         # Model management script
└── README.md               # Complete documentation
```

<img src="https://github.com/sin-boo/localAIchat_Blender/raw/3b9421065a7117b8530a5be4e8e39ba49e6c3913/part_1%20to%202.PNG" alt="Preview" width="600" height="850" align="left"/>


# LocalAIchat Blender ‎ ‎ ‎ ‎ ‎ Add-on

## Introduction

Now that you have the add-on, the next step is to install it.  
I’ll assume you already know how to install a Blender add-on. If not, there are plenty of quick YouTube tutorials that can walk you through it.  

Once installed, we just need to set the **base folder location** inside the add-on settings.  

Currently, this project is still in testing, but let’s give it a try:  
1. Go to the add-on settings.  
2. Set the **base folder** to the directory named `a_assistant`.  
   - This makes the add-on look for the required files inside that folder.  
3. After setting the path, press **Refresh**.  

If everything is set up correctly, it should now work! 🎉  
# LocalAIchat Blender Add-on

<img src="https://github.com/sin-boo/localAIchat_Blender/blob/3c398eaf52494eb5c9cf484766606a63da48211a/part%204.PNG" alt="Preview" width="500" align="left"/>

## Introduction

Now that you have the add-on, the next step is to install it.  
I’ll assume you already know how to install a Blender add-on. If not, there are plenty of quick YouTube tutorials that can walk you through it.  

Once installed, we just need to set the **base folder location** inside the add-on settings.  

Currently, this project is still in testing, but let’s give it a try:  
1. Go to the add-on settings.  
2. Set the **base folder** to the directory named `a_assistant`.  
   - This makes the add-on look for the required files inside that folder.  
3. After setting the path, press **Refresh**.  

If everything is set up correctly, it should now work! 🎉  

---

## Installing Ollama

Next, you’ll need to install **Ollama**, which handles the language models used by this add-on.  

🔗 Download Ollama here: [https://ollama.com/](https://ollama.com/)  

Once Ollama is installed, download the model of your choice.  
⚠️ Keep in mind that **not all models work** with this add-on.  
The ones tested so far are:  
- `gemma3:12b / 8b`  
- `deepseek-r18b`  
- `qwen3-4b / 8b`  

### Setting up your model
1. After downloading a model, place it inside:  
2. In the add-on settings, select this folder as the **file path**.  
3. Press **Extract Model Name from File**.  
4. Then press **Browse Model**.  

🚫 Do **not** press "Start" manually — this will load the model twice.  
Instead, the add-on will automatically start the model when you send your first message.  
































































